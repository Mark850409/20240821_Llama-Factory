version: '3.8'

services:
  llama-factory:
    image: llama-factory:v0.00 # 修改为编译出来的 docker image 名称/版本
    container_name: llama_factory # container 名称
    volumes:
      - C:\WorkSpace\LLaMA-Factory\LLaMA-Factory\huggingface:/root/.cache/huggingface/
      - C:\WorkSpace\LLaMA-Factory\LLaMA-Factory\data:/app/data
      - C:\WorkSpace\LLaMA-Factory\LLaMA-Factory\output:/app/output
      - C:\WorkSpace\LLaMA-Factory\LLaMA-Factory\models:/app/models # 映射自己的models目录
      - C:\WorkSpace\LLaMA-Factory\LLaMA-Factory:/app # 映射自己的models目录
    environment:
      - CUDA_VISIBLE_DEVICES=0,1
      - GRADIO_SERVER_PORT=7864 # webui跑在7864端口上，7860被comfyui占用了
    ports:
      - "7864:7864" # webui跑在7864端口上，7860被comfyui占用了
    ipc: host
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: "all"
            capabilities: [gpu]
    restart: unless-stopped